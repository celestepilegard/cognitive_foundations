<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Attention | Cognitive Foundations</title>
  <meta name="description" content="This is a an OER textbook for introductory to cognitive psychology." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Attention | Cognitive Foundations" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://pilegard.github.io/cogfoundations/images/cover.png" />
  <meta property="og:description" content="This is a an OER textbook for introductory to cognitive psychology." />
  <meta name="github-repo" content="pilegard/cogfoundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Attention | Cognitive Foundations" />
  
  <meta name="twitter:description" content="This is a an OER textbook for introductory to cognitive psychology." />
  <meta name="twitter:image" content="https://pilegard.github.io/cogfoundations/images/cover.png" />

<meta name="author" content="Celeste Pilegard" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="perception.html"/>
<link rel="next" href="short-term-and-working-memory.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/logo.png"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#revisions"><i class="fa fa-check"></i>Revisions</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-1"><i class="fa fa-check"></i>Chapter 1</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-2"><i class="fa fa-check"></i>Chapter 2</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-3"><i class="fa fa-check"></i>Chapter 3</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-4"><i class="fa fa-check"></i>Chapter 4</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-5"><i class="fa fa-check"></i>Chapter 5</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-6"><i class="fa fa-check"></i>Chapter 6</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-7"><i class="fa fa-check"></i>Chapter 7</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-8"><i class="fa fa-check"></i>Chapter 8</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-9"><i class="fa fa-check"></i>Chapter 9</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapter-9-1"><i class="fa fa-check"></i>Chapter 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html"><i class="fa fa-check"></i><b>1</b> History and Research Methods</a>
<ul>
<li class="chapter" data-level="1.1" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#rise-of-cognitive-psychology"><i class="fa fa-check"></i><b>1.1</b> Rise of Cognitive Psychology</a>
<ul>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#analytic-introspection"><i class="fa fa-check"></i>Analytic introspection</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#the-growth-of-psychology"><i class="fa fa-check"></i>The Growth of Psychology</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#cognitive-revolution"><i class="fa fa-check"></i>Cognitive Revolution</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#research-methods-in-psychology"><i class="fa fa-check"></i><b>1.2</b> Research Methods in Psychology</a>
<ul>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#experimental-research"><i class="fa fa-check"></i>Experimental Research</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#correlational-designs"><i class="fa fa-check"></i>Correlational Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#qualitative-designs"><i class="fa fa-check"></i>Qualitative Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#quasi-experimental-designs"><i class="fa fa-check"></i>Quasi-Experimental Designs</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#longitudinal-studies"><i class="fa fa-check"></i>Longitudinal Studies</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#tradeoffs-in-research"><i class="fa fa-check"></i>Tradeoffs in Research</a></li>
<li class="chapter" data-level="" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#research-methods-why-you-need-them"><i class="fa fa-check"></i>Research Methods: Why You Need Them</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="history-and-research-methods.html"><a href="history-and-research-methods.html#glossary"><i class="fa fa-check"></i><b>1.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="perception.html"><a href="perception.html"><i class="fa fa-check"></i><b>2</b> Perception</a>
<ul>
<li class="chapter" data-level="2.1" data-path="perception.html"><a href="perception.html#sensation-and-perception"><i class="fa fa-check"></i><b>2.1</b> Sensation and Perception</a>
<ul>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#seeing"><i class="fa fa-check"></i>Seeing</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#the-sensing-eye-and-the-perceiving-visual-cortex"><i class="fa fa-check"></i>The Sensing Eye and the Perceiving Visual Cortex</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#perceiving-form"><i class="fa fa-check"></i>Perceiving Form</a></li>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#perceiving-depth"><i class="fa fa-check"></i>Perceiving Depth</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="perception.html"><a href="perception.html#accuracy-and-inaccuracy-in-perception"><i class="fa fa-check"></i><b>2.2</b> Accuracy and Inaccuracy in Perception</a>
<ul>
<li class="chapter" data-level="" data-path="perception.html"><a href="perception.html#how-the-perceptual-system-interprets-the-environment"><i class="fa fa-check"></i>How the Perceptual System Interprets the Environment</a></li>
<li class="chapter" data-level="2.2.1" data-path="perception.html"><a href="perception.html#illusions"><i class="fa fa-check"></i><b>2.2.1</b> Illusions</a></li>
<li class="chapter" data-level="2.2.2" data-path="perception.html"><a href="perception.html#the-important-role-of-expectations-in-perception"><i class="fa fa-check"></i><b>2.2.2</b> The Important Role of Expectations in Perception</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="perception.html"><a href="perception.html#glossary-1"><i class="fa fa-check"></i><b>2.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="attention.html"><a href="attention.html"><i class="fa fa-check"></i><b>3</b> Attention</a>
<ul>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#what-is-attention"><i class="fa fa-check"></i>What is Attention?</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#selective-attention"><i class="fa fa-check"></i>Selective Attention</a></li>
<li class="chapter" data-level="" data-path="attention.html"><a href="attention.html#divided-attention-and-multitasking"><i class="fa fa-check"></i>Divided Attention and Multitasking</a></li>
<li class="chapter" data-level="3.1" data-path="attention.html"><a href="attention.html#glossary-2"><i class="fa fa-check"></i><b>3.1</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html"><i class="fa fa-check"></i><b>4</b> Short-term and Working Memory</a>
<ul>
<li class="chapter" data-level="4.1" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html#short-term-memory"><i class="fa fa-check"></i><b>4.1</b> Short-Term Memory</a>
<ul>
<li class="chapter" data-level="" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html#from-short-term-memory-to-baddeleys-working-memory-model"><i class="fa fa-check"></i>From Short-Term Memory to Baddeley’s Working Memory Model</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html#working-memory"><i class="fa fa-check"></i><b>4.2</b> Working Memory</a>
<ul>
<li class="chapter" data-level="" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html#the-episodic-buffer"><i class="fa fa-check"></i>The episodic buffer</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="short-term-and-working-memory.html"><a href="short-term-and-working-memory.html#glossary-3"><i class="fa fa-check"></i><b>4.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="long-term-memory.html"><a href="long-term-memory.html"><i class="fa fa-check"></i><b>5</b> Long-term Memory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="long-term-memory.html"><a href="long-term-memory.html#working-memory-vs.-long-term-memory"><i class="fa fa-check"></i><b>5.1</b> WORKING MEMORY VS. LONG-TERM MEMORY</a>
<ul>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#the-serial-position-curve"><i class="fa fa-check"></i>The Serial Position Curve</a></li>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#explicit-memory"><i class="fa fa-check"></i>Explicit Memory</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#implicit-memory"><i class="fa fa-check"></i>Implicit Memory</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="long-term-memory.html"><a href="long-term-memory.html#make-image"><i class="fa fa-check"></i><b>5.1.1</b> MAKE IMAGE</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="long-term-memory.html"><a href="long-term-memory.html#encoding-retrieval-and-consolidation"><i class="fa fa-check"></i><b>5.2</b> Encoding, Retrieval, and Consolidation</a>
<ul>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#encoding"><i class="fa fa-check"></i>Encoding</a></li>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#retrieval"><i class="fa fa-check"></i>Retrieval</a></li>
<li class="chapter" data-level="" data-path="long-term-memory.html"><a href="long-term-memory.html#consolidation"><i class="fa fa-check"></i>Consolidation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="long-term-memory.html"><a href="long-term-memory.html#glossary-4"><i class="fa fa-check"></i><b>5.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="memory-in-context.html"><a href="memory-in-context.html"><i class="fa fa-check"></i><b>6</b> Memory in Context</a>
<ul>
<li class="chapter" data-level="6.1" data-path="memory-in-context.html"><a href="memory-in-context.html#kinds-of-memory-biases"><i class="fa fa-check"></i><b>6.1</b> Kinds of Memory Biases</a>
<ul>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#schematic-processing-distortions-based-on-expectations"><i class="fa fa-check"></i>Schematic Processing: Distortions Based on Expectations</a></li>
<li class="chapter" data-level="6.1.1" data-path="memory-in-context.html"><a href="memory-in-context.html#source-monitoring"><i class="fa fa-check"></i><b>6.1.1</b> Source Monitoring</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#false-memory"><i class="fa fa-check"></i>False Memory</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#the-misinformation-effect"><i class="fa fa-check"></i>The Misinformation effect</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#flashbulb-memories"><i class="fa fa-check"></i>Flashbulb Memories</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="memory-in-context.html"><a href="memory-in-context.html#forgetting"><i class="fa fa-check"></i><b>6.2</b> Forgetting</a>
<ul>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#encoding-failure"><i class="fa fa-check"></i>Encoding Failure</a></li>
<li class="chapter" data-level="" data-path="memory-in-context.html"><a href="memory-in-context.html#interference"><i class="fa fa-check"></i>Interference</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="memory-in-context.html"><a href="memory-in-context.html#glossary-5"><i class="fa fa-check"></i><b>6.3</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="knowledge.html"><a href="knowledge.html"><i class="fa fa-check"></i><b>7</b> Knowledge</a>
<ul>
<li class="chapter" data-level="7.1" data-path="knowledge.html"><a href="knowledge.html#nature-of-categories"><i class="fa fa-check"></i><b>7.1</b> Nature of Categories</a>
<ul>
<li class="chapter" data-level="" data-path="knowledge.html"><a href="knowledge.html#typicality"><i class="fa fa-check"></i>Typicality</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="knowledge.html"><a href="knowledge.html#theories-of-concept-representation"><i class="fa fa-check"></i><b>7.2</b> Theories of Concept Representation</a></li>
<li class="chapter" data-level="7.3" data-path="knowledge.html"><a href="knowledge.html#organization-of-concepts"><i class="fa fa-check"></i><b>7.3</b> Organization of Concepts</a>
<ul>
<li class="chapter" data-level="" data-path="knowledge.html"><a href="knowledge.html#semantic-networks"><i class="fa fa-check"></i>Semantic Networks</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="knowledge.html"><a href="knowledge.html#glossary-6"><i class="fa fa-check"></i><b>7.4</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="language.html"><a href="language.html"><i class="fa fa-check"></i><b>8</b> Language</a>
<ul>
<li class="chapter" data-level="8.1" data-path="language.html"><a href="language.html#what-is-language"><i class="fa fa-check"></i><b>8.1</b> What is Language?</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#linguistic-diversity"><i class="fa fa-check"></i>Linguistic Diversity</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#the-components-of-language"><i class="fa fa-check"></i>The Components of Language</a></li>
<li class="chapter" data-level="8.1.1" data-path="language.html"><a href="language.html#examples-in-which-syntax-is-correct-but-the-interpretation-can-be-ambiguous"><i class="fa fa-check"></i><b>8.1.1</b> Examples in Which Syntax Is Correct but the Interpretation Can Be Ambiguous</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="language.html"><a href="language.html#mechanisms-of-language"><i class="fa fa-check"></i><b>8.2</b> Mechanisms of Language</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#language-processing"><i class="fa fa-check"></i>Language Processing</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#language-production"><i class="fa fa-check"></i>Language Production</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="language.html"><a href="language.html#language-acquisition"><i class="fa fa-check"></i><b>8.3</b> Language Acquisition</a>
<ul>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#the-importance-of-language-in-cognitive-development"><i class="fa fa-check"></i>The Importance of Language in Cognitive Development</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#bilingualism"><i class="fa fa-check"></i>Bilingualism</a></li>
<li class="chapter" data-level="" data-path="language.html"><a href="language.html#adult-language-acquisition"><i class="fa fa-check"></i>Adult Language Acquisition</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="language.html"><a href="language.html#language-and-thought"><i class="fa fa-check"></i><b>8.4</b> Language and Thought</a></li>
<li class="chapter" data-level="8.5" data-path="language.html"><a href="language.html#glossary-7"><i class="fa fa-check"></i><b>8.5</b> Glossary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html"><i class="fa fa-check"></i><b>9</b> Reasoning and Decision Making</a>
<ul>
<li class="chapter" data-level="9.1" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#deductive-reasoning"><i class="fa fa-check"></i><b>9.1</b> Deductive reasoning</a>
<ul>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#categorical-syllogisms"><i class="fa fa-check"></i>Categorical syllogisms</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#conditional-syllogisms"><i class="fa fa-check"></i>Conditional syllogisms</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#inductive-reasoning"><i class="fa fa-check"></i><b>9.2</b> Inductive reasoning</a>
<ul>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#forms-of-inductive-reasoning"><i class="fa fa-check"></i>Forms of inductive reasoning</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#reliability-of-conclusions"><i class="fa fa-check"></i>Reliability of conclusions</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#processes-and-constraints"><i class="fa fa-check"></i>Processes and constraints</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#induction-vs.-deduction"><i class="fa fa-check"></i>Induction vs. deduction</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#decision-making"><i class="fa fa-check"></i><b>9.3</b> Decision making</a>
<ul>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#theories-of-decision-making"><i class="fa fa-check"></i>Theories of Decision Making</a></li>
<li class="chapter" data-level="" data-path="reasoning-and-decision-making.html"><a href="reasoning-and-decision-making.html#constructed-preferences"><i class="fa fa-check"></i>Constructed Preferences</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="problem-solving.html"><a href="problem-solving.html"><i class="fa fa-check"></i><b>10</b> Problem Solving</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#well-defined-problems"><i class="fa fa-check"></i>Well-defined Problems</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#ill-defined-problems"><i class="fa fa-check"></i>Ill-defined Problems</a></li>
<li class="chapter" data-level="10.1" data-path="problem-solving.html"><a href="problem-solving.html#restructuring-the-gestalt-approach"><i class="fa fa-check"></i><b>10.1</b> Restructuring: The Gestalt Approach</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#how-is-a-problem-represented-in-the-mind"><i class="fa fa-check"></i>How is a problem represented in the mind?</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#insight"><i class="fa fa-check"></i>Insight</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#fixation"><i class="fa fa-check"></i>Fixation</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="problem-solving.html"><a href="problem-solving.html#solving-problems-by-analogy"><i class="fa fa-check"></i><b>10.2</b> Solving Problems by Analogy</a></li>
<li class="chapter" data-level="10.3" data-path="problem-solving.html"><a href="problem-solving.html#how-do-experts-solve-problems"><i class="fa fa-check"></i><b>10.3</b> How do Experts Solve Problems?</a>
<ul>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#knowledge-1"><i class="fa fa-check"></i>Knowledge</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#organization"><i class="fa fa-check"></i>Organization</a></li>
<li class="chapter" data-level="" data-path="problem-solving.html"><a href="problem-solving.html#analysis"><i class="fa fa-check"></i>Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cognitive Foundations</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="attention" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Attention<a href="attention.html#attention" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><img src="images/ch3/fig0.png" width="100%" style="display: block; margin: auto;" />
We use the term “attention“ all the time, but what processes or abilities does that concept really refer to? This chapter will focus on how attention allows us to select certain parts of our environment and ignore other parts, and what happens to the ignored information. A key concept is the idea that we are limited in how much we can do at any one time. So we will also consider what happens when someone tries to do several things at once, such as driving while using electronic devices. Chapter 3 License and Attribution</p>
<div id="learning-objectives-3" class="section level5 unnumbered hasAnchor learningobjectives">
<h5>LEARNING OBJECTIVES<a href="attention.html#learning-objectives-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li>XX</li>
<li>XX</li>
</ol>
</div>
<div id="what-is-attention" class="section level3 unnumbered hasAnchor">
<h3>What is Attention?<a href="attention.html#what-is-attention" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig1.jpg" alt="Are you reading these words right here right now? If so, it’s only because you directed your attention toward them. [Image: CC BY 2.0,  HYPERLINK &quot;https://goo.gl/BRvSA7%5D&quot;https://goo.gl/BRvSA7]" width="60%" />
<p class="caption">
(#fig:fig3.1)Are you reading these words right here right now? If so, it’s only because you directed your attention toward them. [Image: CC BY 2.0, HYPERLINK “<a href="https://goo.gl/BRvSA7%5D%22https://goo.gl/BRvSA7" class="uri">https://goo.gl/BRvSA7%5D"https://goo.gl/BRvSA7</a>]
</p>
</div>
<p>Before we begin exploring attention in its various forms, take a moment to consider how you think about the concept. How would you define attention, or how do you use the term? We certainly use the word very frequently in our everyday language: “ATTENTION! USE ONLY AS DIRECTED!” warns the label on the medicine bottle, meaning be alert to possible danger. “Pay attention!” pleads the weary seventh-grade teacher, not warning about danger (with possible exceptions, depending on the teacher) but urging the students to focus on the task at hand. We may refer to a child who is easily distracted as having an attention disorder, although we also are told that Americans have an attention span of about 8 seconds, down from 12 seconds in 2000, suggesting that we all have trouble sustaining concentration for any amount of time (from www.Statisticbrain.com). How that number was determined is not clear from the Web site, nor is it clear how attention span in the goldfish—9 seconds!—was measured, but the fact that our average span reportedly is less than that of a goldfish is intriguing, to say the least.</p>
<p>William James wrote extensively about attention in the late 1800s. An often quoted passage (James, 1890/1983) beautifully captures how intuitively obvious the concept of attention is, while it remains very difficult to define in measurable, concrete terms:</p>
<blockquote>
<p>Everyone knows what attention is. It is the taking possession by the mind, in clear and vivid form, of one out of what seem several simultaneously possible objects or trains of thought. Focalization, concentration of consciousness are of its essence. It implies withdrawal from some things in order to deal effectively with others. (pp. 381–382)</p>
</blockquote>
<p>Notice that this description touches on the conscious nature of attention, as well as the notion that what is in consciousness is often controlled voluntarily but can also be determined by events that capture our attention. Implied in this description is the idea that we seem to have a [limited capacity] for information processing, and <em>that we can only attend to or be consciously aware of a small amount of information at any given time</em>.</p>
<p>Many aspects of attention have been studied in the field of psychology. In some respects, we define different types of attention by the nature of the task used to study it. For example, a crucial issue in World War II was how long an individual could remain highly alert and accurate while watching a radar screen for enemy planes, and this problem led psychologists to study how attention works under such conditions. When watching for a rare event, it is easy to allow concentration to lag. (This a continues to be a challenge today for TSA agents, charged with looking at images of the contents of your carry-on items in search of knives, guns, or shampoo bottles larger than 3 oz.) Attention in the context of this type of search task refers to the level of <em>sustained attention</em> or <em>vigilance</em> one can maintain. In contrast, <a href="attention.html#divided-attention-tasks">divided attention tasks</a> allow us to <em>determine how well individuals can attend to many sources of information at once</em>. [Spatial attention] refers specifically to <em>how we focus on one part of our environment and how we move attention to other locations in the environment</em>. These are all examples of different aspects of attention, but an implied element of most of these ideas is the concept of selective attention; some information is attended to while other information is intentionally blocked out. This module will focus on important issues in selective and divided attention, addressing these questions:</p>
<p>Can we pay attention to several sources of information at once, or do we have a limited capacity for information?
* How do we select what to pay attention to?
* What happens to information that we try to ignore?
* Can we learn to divide attention between multiple tasks?</p>
</div>
<div id="selective-attention" class="section level3 unnumbered hasAnchor">
<h3>Selective Attention<a href="attention.html#selective-attention" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="the-cocktail-party" class="section level4 unnumbered hasAnchor">
<h4>The Cocktail Party<a href="attention.html#the-cocktail-party" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><a href="attention.html#selective-attention">Selective attention</a> is <em>the ability to select certain stimuli in the environment to process, while ignoring distracting information</em>. One way to get an intuitive sense of how attention works is to consider situations in which attention is used. A party provides an excellent example for our purposes. Many people may be milling around, there is a dazzling variety of colors and sounds and smells, the buzz of many conversations is striking. There are so many conversations going on; how is it possible to select just one and follow it? You don’t have to be looking at the person talking; you may be listening with great interest to some gossip while pretending not to hear.</p>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig2.jpg" alt="Beyond just hearing your name from the clamor at a party, other words or concepts, particularly unusual or significant ones to you, can also snag your attention. [Image: Ross,  HYPERLINK &quot;https://goo.gl/TVDfTn,&quot;https://goo.gl/TVDfTn, CC BY-NC-SA 2.0,  HYPERLINK &quot;https://goo.gl/Toc0ZF%5D&quot;https://goo.gl/Toc0ZF]" width="60%" />
<p class="caption">
(#fig:fig3.2)Beyond just hearing your name from the clamor at a party, other words or concepts, particularly unusual or significant ones to you, can also snag your attention. [Image: Ross, HYPERLINK “<a href="https://goo.gl/TVDfTn" class="uri">https://goo.gl/TVDfTn</a>,”<a href="https://goo.gl/TVDfTn" class="uri">https://goo.gl/TVDfTn</a>, CC BY-NC-SA 2.0, HYPERLINK “<a href="https://goo.gl/Toc0ZF%5D%22https://goo.gl/Toc0ZF" class="uri">https://goo.gl/Toc0ZF%5D"https://goo.gl/Toc0ZF</a>]
</p>
</div>
<p>However, once you are engaged in conversation with someone, you quickly become aware that you cannot also listen to other conversations at the same time. You also are probably not aware of how tight your shoes feel or of the smell of a nearby flower arrangement. On the other hand, if someone behind you mentions your name, you typically notice it immediately and may start attending to that (much more interesting) conversation. This situation highlights an interesting set of observations. We have an amazing ability to select and track one voice, visual object, etc., even when a million things are competing for our attention, but at the same time, we seem to be limited in how much we can attend to at one time, which in turn suggests that attention is crucial in selecting what is important. How does it all work?</p>
</div>
<div id="dichotic-listening-studies" class="section level4 unnumbered hasAnchor">
<h4>Dichotic Listening Studies<a href="attention.html#dichotic-listening-studies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This cocktail party scenario is the quintessential example of selective attention, and it is essentially what some early researchers tried to replicate under controlled laboratory conditions as a starting point for understanding the role of attention in perception (e.g., <span class="citation">Cherry (<a href="#ref-Cherry1953" role="doc-biblioref">1953</a>)</span>; <span class="citation">Moray (<a href="#ref-Moray1959" role="doc-biblioref">1959</a>)</span>). In particular, they used [dichotic listening] and [shadowing tasks] to evaluate the selection process. [Dichotic listening] simply refers to <em>the situation when two messages are presented simultaneously to an individual, with one message in each ear</em>. In order to control which message the person attends to, the individual is asked to repeat back or “shadow” one of the messages as he hears it. For example, let’s say that a story about a camping trip is presented to John’s left ear, and a story about Abe Lincoln is presented to his right ear. The typical dichotic listening task would have John repeat the story presented to one ear as he hears it. Can he do that without being distracted by the information in the other ear?</p>
<p>People can become pretty good at the shadowing task, and they can easily report the content of the message that they attend to. But what happens to the ignored message? Typically, people can tell you if the ignored message was a man’s or a woman’s voice, or other physical characteristics of the speech, but they cannot tell you what the message was about. In fact, many studies have shown that people in a shadowing task were not aware of a change in the language of the message (e.g., from English to German; <span class="citation">Cherry (<a href="#ref-Cherry1953" role="doc-biblioref">1953</a>)</span>), and they didn’t even notice when the same word was repeated in the unattended ear more than 35 times <span class="citation">(<a href="#ref-Moray1959" role="doc-biblioref">Moray, 1959</a>)</span>! Only the basic physical characteristics, such as the pitch of the unattended message, could be reported.</p>
<p>On the basis of these types of experiments, it seems that we can answer the first question about how much information we can attend to very easily: not very much. We clearly have a limited capacity for processing information for meaning, making the selection process all the more important. The question becomes: How does this selection process work?</p>
</div>
<div id="models-of-selective-attention" class="section level4 unnumbered hasAnchor">
<h4>Models of Selective Attention<a href="attention.html#models-of-selective-attention" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Broadbent’s Filter Model. Many researchers have investigated how selection occurs and what happens to ignored information. Donald Broadbent was one of the first to try to characterize the selection process. His Filter Model was based on the dichotic listening tasks described above as well as other types of experiments (Broadbent, 1958). He found that people select information on the basis of physical features: the sensory channel (or ear) that a message was coming in, the pitch of the voice, the color or font of a visual message. People seemed vaguely aware of the physical features of the unattended information, but had no knowledge of the meaning. As a result, Broadbent argued that selection occurs very early, with no additional processing for the unselected information. A flowchart of the model might look like this:</p>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig3.png" alt="Figure 1. This figure shows information going in both the left and right ears. Some basic sensory information, such as pitch, is processed, but the filter only allows the information from one ear to be processed further. Only the information from the left ear is transferred to short-term memory (STM) and conscious awareness, and then further processed for meaning. That means that the ignored information never makes it beyond a basic physical analysis." width="60%" />
<p class="caption">
(#fig:fig3.3)Figure 1. This figure shows information going in both the left and right ears. Some basic sensory information, such as pitch, is processed, but the filter only allows the information from one ear to be processed further. Only the information from the left ear is transferred to short-term memory (STM) and conscious awareness, and then further processed for meaning. That means that the ignored information never makes it beyond a basic physical analysis.
</p>
</div>
</div>
<div id="treismans-attenuation-model" class="section level4 unnumbered hasAnchor">
<h4>Treisman’s Attenuation Model<a href="attention.html#treismans-attenuation-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Broadbent’s model makes sense, but if you think about it you already know that it cannot account for all aspects of the Cocktail Party Effect. What doesn’t fit? The fact is that you tend to hear your own name when it is spoken by someone, even if you are deeply engaged in a conversation. We mentioned earlier that people in a shadowing experiment were unaware of a word in the unattended ear that was repeated many times—and yet many people noticed their own name in the unattended ear even it occurred only once.</p>
<p>Anne Treisman (1960) <span class="citation">(<a href="#ref-Treisman1960" role="doc-biblioref"><strong>Treisman1960?</strong></a>)</span> carried out a number of dichotic listening experiments in which she presented two different stories to the two ears. As usual, she asked people to shadow the message in one ear. As the stories progressed, however, she switched the stories to the opposite ears. Treisman found that individuals spontaneously followed the story, or the content of the message, when it shifted from the left ear to the right ear. Then they realized they were shadowing the wrong ear and switched back.</p>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig4.png" alt="Figure 2. Early selection model." width="60%" />
<p class="caption">
(#fig:fig3.4)Figure 2. Early selection model.
</p>
</div>
<p>Results like this, and the fact that you tend to hear meaningful information even when you aren’t paying attention to it, suggest that we do monitor the unattended information to some degree on the basis of its meaning. Therefore, the filter theory can’t be right to suggest that unattended information is completely blocked at the sensory analysis level. Instead, Treisman suggested that selection starts at the physical or perceptual level, but that the unattended information is not blocked completely, it is just weakened or attenuated. As a result, highly meaningful or pertinent information in the unattended ear will get through the filter for further processing at the level of meaning. @ref(fig:fig3.4) shows information going in both ears, and in this case there is no filter that completely blocks nonselected information. Instead, selection of the left ear information strengthens that material, while the nonselected information in the right ear is weakened. However, if the preliminary analysis shows that the nonselected information is especially pertinent or meaningful (such as your own name), then the Attenuation Control will instead strengthen the more meaningful information.</p>
</div>
<div id="late-selection-models" class="section level4 unnumbered hasAnchor">
<h4>Late Selection Models<a href="attention.html#late-selection-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig5.png" alt="Figure 3. Late selection model." width="60%" />
<p class="caption">
(#fig:fig3.5)Figure 3. Late selection model.
</p>
</div>
<p>Other selective attention models have been proposed as well. A late selection or response selection model proposed by <span class="citation">Deutsch &amp; Deutsch (<a href="#ref-Deutsch1963" role="doc-biblioref">1963</a>)</span> suggests that all information in the unattended ear is processed on the basis of meaning, not just the selected or highly pertinent information. However, only the information that is relevant for the task response gets into conscious awareness. This model is consistent with ideas of subliminal perception; in other words, that you don’t have to be aware of or attending a message for it to be fully processed for meaning.</p>
<p>You might notice that @ref(fig:fig3.5) looks a lot like the Early Selection model—only the location of the selective filter has changed, with the assumption that analysis of meaning occurs before selection occurs, but only the selected information becomes conscious.</p>
</div>
<div id="multimode-model" class="section level4 unnumbered hasAnchor">
<h4>Multimode Model<a href="attention.html#multimode-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Why did researchers keep coming up with different models? Because no model really seemed to account for all the data, some of which indicates that nonselected information is blocked completely, whereas other studies suggest that it can be processed for meaning. The multimode model addresses this apparent inconsistency, suggesting that the stage at which selection occurs can change depending on the task. <span class="citation">Johnston &amp; Heinz (<a href="#ref-Johnston1978" role="doc-biblioref">1978</a>)</span> demonstrated that under some conditions, we can select what to attend to at a very early stage and we do not process the content of the unattended message very much at all. Analyzing physical information, such as attending to information based on whether it is a male or female voice, is relatively easy; it occurs automatically, rapidly, and doesn’t take much effort. Under the right conditions, we can select what to attend to on the basis of the meaning of the messages. However, the late selection option—processing the content of all messages before selection—is more difficult and requires more effort. The benefit, though, is that we have the flexibility to change how we deploy our attention depending upon what we are trying to accomplish, which is one of the greatest strengths of our cognitive system.</p>
<p>This discussion of selective attention has focused on experiments using auditory material, but the same principles hold for other perceptual systems as well. <span class="citation">(<a href="#ref-Neisser1979" role="doc-biblioref"><strong>Neisser1979?</strong></a>)</span> investigated some of the same questions with visual materials by superimposing two semi-transparent video clips and asking viewers to attend to just one series of actions. As with the auditory materials, viewers often were unaware of what went on in the other clearly visible video. Twenty years later, <span class="citation">Simons &amp; Chabris (<a href="#ref-Simons1999" role="doc-biblioref">1999</a>)</span> explored and expanded these findings using similar techniques, and triggered a flood of new work in an area referred to as inattentional blindness.</p>
</div>
<div id="subliminal-perception" class="section level4 unnumbered hasAnchor fyi">
<h4>Subliminal Perception<a href="attention.html#subliminal-perception" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The idea of subliminal perception—that stimuli presented below the threshold for awareness can influence thoughts, feelings, or actions—is a fascinating and kind of creepy one. Can messages you are unaware of, embedded in movies or ads or the music playing in the grocery store, really influence what you buy? Many such claims of the power of subliminal perception have been made. One of the most famous came from a market researcher who claimed that the message “Eat Popcorn” briefly flashed throughout a movie increased popcorn sales by more than 50%, although he later admitted that the study was made up <span class="citation">(<a href="#ref-Merikle2000" role="doc-biblioref"><strong>Merikle2000?</strong></a>)</span>. Psychologists have worked hard to investigate whether this is a valid phenomenon. Studying subliminal perception is more difficult than it might seem, because of the difficulty of establishing what the threshold for consciousness is or of even determining what type of threshold is important; for example, Cheesman and <span class="citation">(<a href="#ref-Merikle1984" role="doc-biblioref"><strong>Merikle1984?</strong></a>)</span> and <span class="citation">(<a href="#ref-Merikle1986" role="doc-biblioref"><strong>Merikle1986?</strong></a>)</span> make an important distinction between objective and subjective thresholds. The bottom line is that there is some evidence that individuals can be influenced by stimuli they are not aware of, but how complex the stimuli can be or the extent to which unconscious material can affect behavior is not settled <span class="citation">(<a href="#ref-Greenwald1992" role="doc-biblioref">Greenwald, 1992</a>; e.g., <a href="#ref-Bargh2008" role="doc-biblioref"><strong>Bargh2008?</strong></a>; <a href="#ref-Merikle2000" role="doc-biblioref"><strong>Merikle2000?</strong></a>)</span>.</p>
</div>
</div>
<div id="divided-attention-and-multitasking" class="section level3 unnumbered hasAnchor">
<h3>Divided Attention and Multitasking<a href="attention.html#divided-attention-and-multitasking" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In spite of the evidence of our limited capacity, we all like to think that we can do several things at once. Some people claim to be able to multitask without any problem: reading a textbook while watching television and talking with friends; talking on the phone while playing computer games; texting while driving. The fact is that we sometimes can seem to juggle several things at once, but the question remains whether dividing attention in this way impairs performance.
Is it possible to overcome the limited capacity that we experience when engaging in cognitive tasks? We know that with extensive practice, we can acquire skills that do not appear to require conscious attention. As we walk down the street, we don’t need to think consciously about what muscle to contract in order to take the next step. Indeed, paying attention to automated skills can lead to a breakdown in performance, or “choking” <span class="citation">(e.g., <a href="#ref-Beilock2001" role="doc-biblioref">Beilock &amp; Carr, 2001</a>)</span>. But what about higher level, more mentally demanding tasks: Is it possible to learn to perform two complex tasks at the same time?</p>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig6.jpg" alt="Unless a task is fully automated, some researchers suggest that “multi-tasking” doesn’t really exist; you are just rapidly switching your attention back and forth between tasks. [Image: CC0 Public Domain,  HYPERLINK &quot;https://goo.gl/m25gce%5D&quot;https://goo.gl/m25gce]" width="60%" />
<p class="caption">
(#fig:fig3.6)Unless a task is fully automated, some researchers suggest that “multi-tasking” doesn’t really exist; you are just rapidly switching your attention back and forth between tasks. [Image: CC0 Public Domain, HYPERLINK “<a href="https://goo.gl/m25gce%5D%22https://goo.gl/m25gce" class="uri">https://goo.gl/m25gce%5D"https://goo.gl/m25gce</a>]
</p>
</div>
<div id="divided-attention-tasks" class="section level4 unnumbered hasAnchor">
<h4>Divided Attention Tasks<a href="attention.html#divided-attention-tasks" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Unless a task is fully automated, some researchers suggest that “multi-tasking” doesn’t really exist; you are just rapidly switching your attention back and forth between tasks. [Image: CC0 Public Domain, <a href="https://goo.gl/m25gce" class="uri">https://goo.gl/m25gce</a>]</p>
<p>In a classic study that examined this type of divided attention task, two participants were trained to take dictation for spoken words while reading unrelated material for comprehension <span class="citation">(<a href="#ref-Spelke1976" role="doc-biblioref">Spelke et al., 1976</a>)</span>. In divided attention tasks such as these, each task is evaluated separately, in order to determine baseline performance when the individual can allocate as many cognitive resources as necessary to one task at a time. Then performance is evaluated when the two tasks are performed simultaneously. A decrease in performance for either task would suggest that even if attention can be divided or switched between the tasks, the cognitive demands are too great to avoid disruption of performance. (We should note here that divided attention tasks are designed, in principle, to see if two tasks can be carried out simultaneously. A related research area looks at task switching and how well we can switch back and forth among different tasks <span class="citation">(e.g., <a href="#ref-Monsell2003" role="doc-biblioref"><strong>Monsell2003?</strong></a>)</span>. It turns out that switching itself is cognitively demanding and can impair performance.</p>
<p>The focus of the <span class="citation">Spelke et al. (<a href="#ref-Spelke1976" role="doc-biblioref">1976</a>)</span> study was whether individuals could learn to perform two relatively complex tasks concurrently, without impairing performance. The participants received plenty of practice—the study lasted 17 weeks and they had a 1-hour session each day, 5 days a week. These participants were able to learn to take dictation for lists of words and read for comprehension without affecting performance in either task, and the authors suggested that perhaps there are not fixed limits on our attentional capacity. However, changing the tasks somewhat, such as reading aloud rather than silently, impaired performance initially, so this multitasking ability may be specific to these well-learned tasks. Indeed, not everyone could learn to perform two complex tasks without performance costs <span class="citation">(<a href="#ref-Hirst1978" role="doc-biblioref"><strong>Hirst1978?</strong></a>)</span>, although the fact that some can is impressive.</p>
</div>
<div id="distracted-driving" class="section level4 unnumbered hasAnchor">
<h4>Distracted Driving<a href="attention.html#distracted-driving" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>More relevant to our current lifestyles are questions about multitasking while texting or having cell phone conversations. Research designed to investigate, under controlled conditions, multitasking while driving has revealed some surprising results. Certainly there are many possible types of distractions that could impair driving performance, such as applying makeup using the rearview mirror, attempting (usually in vain) to stop the kids in the backseat from fighting, fiddling with the CD player, trying to negotiate a handheld cell phone, a cigarette, and a soda all at once, eating a bowl of cereal while driving (!). But we tend to have a strong sense that we CAN multitask while driving, and cars are being built with more and more technological capabilities that encourage multitasking. How good are we at dividing attention in these cases?</p>
<div class="figure" style="text-align: center">
<img src="images/ch3/fig7.jpeg" alt="If you look at your phone for just 5 seconds while driving at 55mph, that means you have driven the length of a football field without looking at the road. [Image: CC0 Public Domain, https://goo.gl/m25gce] " width="60%" />
<p class="caption">
(#fig:fig3.7)If you look at your phone for just 5 seconds while driving at 55mph, that means you have driven the length of a football field without looking at the road. [Image: CC0 Public Domain, <a href="https://goo.gl/m25gce" class="uri">https://goo.gl/m25gce</a>]
</p>
</div>
<p>Most people acknowledge the distraction caused by texting while driving and the reason seems obvious: Your eyes are off the road and your hands and at least one hand (often both) are engaged while texting. However, the problem is not simply one of occupied hands or eyes, but rather that the cognitive demands on our limited capacity systems can seriously impair driving performance <span class="citation">(<a href="#ref-Strayer2011" role="doc-biblioref">Strayer et al., 2011</a>)</span>. The effect of a cell phone conversation on performance (such as not noticing someone’s brake lights or responding more slowly to them) is just as significant when the individual is having a conversation with a hands-free device as with a handheld phone; the same impairments do not occur when listening to the radio or a book on tape <span class="citation">(<a href="#ref-Strayer2001" role="doc-biblioref">Strayer &amp; Johnston, 2001</a>)</span>. Moreover, studies using eye-tracking devices have shown that drivers are less likely to later recognize objects that they did look at when using a cell phone while driving <span class="citation">(<a href="#ref-Strayer" role="doc-biblioref"><strong>Strayer?</strong></a>)</span>. These findings demonstrate that cognitive distractions such as cell phone conversations can produce inattentional blindness, or a lack of awareness of what is right before your eyes (see also, <span class="citation">Simons &amp; Chabris (<a href="#ref-Simons1999" role="doc-biblioref">1999</a>)</span>). Sadly, although we all like to think that we can multitask while driving, in fact the percentage of people who can truly perform cognitive tasks without impairing their driving performance is estimated to be about 2% (<span class="citation">Watson &amp; Strayer (<a href="#ref-Watson2010" role="doc-biblioref">2010</a>)</span>).</p>
<p>It may be useful to think of attention as a mental resource, one that is needed to focus on and fully process important information, especially when there is a lot of distracting “noise” threatening to obscure the message. Our selective attention system allows us to find or track an object or conversation in the midst of distractions. Whether the selection process occurs early or late in the analysis of those events has been the focus of considerable research, and in fact how selection occurs may very well depend on the specific conditions. With respect to divided attention, in general we can only perform one cognitively demanding task at a time, and we may not even be aware of unattended events even though they might seem too obvious to miss (check out some examples in the Outside Resources below). This type of inattention blindness can occur even in well-learned tasks, such as driving while talking on a cell phone. Understanding how attention works is clearly important, even for our everyday lives.</p>
<div id="key-takeaways-3" class="section level5 unnumbered hasAnchor takeaways">
<h5>Key Takeaways<a href="attention.html#key-takeaways-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>a</li>
<li>b</li>
</ul>
</div>
<div id="exercises-3" class="section level5 unnumbered hasAnchor exercises">
<h5>Exercises<a href="attention.html#exercises-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ol style="list-style-type: decimal">
<li>a</li>
<li>b</li>
</ol>
</div>
</div>
</div>
<div id="glossary-2" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Glossary<a href="attention.html#glossary-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Beilock2001" class="csl-entry">
Beilock, S. L., &amp; Carr, T. H. (2001). On the fragility of skilled performance: What governs choking under pressure? <em>J. Exp. Psychol. Gen.</em>, <em>130</em>(4), 701–725.
</div>
<div id="ref-Cherry1953" class="csl-entry">
Cherry, E. C. (1953). Some experiments on the recognition of speech, with one and with two ears. <em>Journal of the Acoustical Society of America</em>, <em>25</em>, 975–979.
</div>
<div id="ref-Deutsch1963" class="csl-entry">
Deutsch, J. A., &amp; Deutsch, D. (1963). Attention: Some theoretical considerations. <em>Psychol. Rev.</em>, <em>70</em>(1), 80–90.
</div>
<div id="ref-Greenwald1992" class="csl-entry">
Greenwald, A. G. (1992). New look 3: Unconscious cognition reclaimed. <em>Am. Psychol.</em>, <em>47</em>(6), 766–779.
</div>
<div id="ref-Johnston1978" class="csl-entry">
Johnston, W. A., &amp; Heinz, S. P. (1978). Flexibility and capacity demands of attention. <em>J. Exp. Psychol. Gen.</em>, <em>107</em>(4), 420–435.
</div>
<div id="ref-Moray1959" class="csl-entry">
Moray, N. (1959). Attention in dichotic listening: Affective cues and the influence of instructions. <em>Q. J. Exp. Psychol.</em>, <em>11</em>(1), 56–60.
</div>
<div id="ref-Simons1999" class="csl-entry">
Simons, D. J., &amp; Chabris, C. F. (1999). Gorillas in our midst: Sustained inattentional blindness for dynamic events. <em>Perception</em>, <em>28</em>(9), 1059–1074.
</div>
<div id="ref-Spelke1976" class="csl-entry">
Spelke, E., Hirst, W., &amp; Neisser, U. (1976). Skills of divided attention. <em>Cognition</em>, <em>4</em>(3), 215–230.
</div>
<div id="ref-Strayer2001" class="csl-entry">
Strayer, D. L., &amp; Johnston, W. A. (2001). Driven to distraction: Dual-task studies of simulated driving and conversing on a cellular telephone. <em>Psychol. Sci.</em>, <em>12</em>(6), 462–466.
</div>
<div id="ref-Strayer2011" class="csl-entry">
Strayer, D. L., Watson, J. M., &amp; Drews, F. A. (2011). Cognitive distraction while multitasking in the automobile. In <em>Advances in research and theory</em> (pp. 29–58). Elsevier.
</div>
<div id="ref-Watson2010" class="csl-entry">
Watson, J. M., &amp; Strayer, D. L. (2010). Supertaskers: Profiles in extraordinary multitasking ability. <em>Psychon. Bull. Rev.</em>, <em>17</em>(4), 479–485.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="perception.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="short-term-and-working-memory.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pilegard/cogfoundations/edit/main/03-attention.Rmd",
"text": "Suggest an edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["https://github.com/pilegard/cogfoundations/raw/main/03-attention.Rmd"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
